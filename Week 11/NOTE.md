# Week 11 Notes

本周主要介绍了 `CSS` 的知识架构，首先使用了一个简单的 `in-browser` 的 `js` 脚本来实现了 `w3.org/TR` 站点上的与 `CSS` 有关的文章标题和链接的抓取。之后按照 `2.1` - `3.0` 规范中的语法产生式，常用规则分类，伪元素，伪类等常见 `CSS` 范畴理论知识。于此同时也介绍了选择器的优先级计算在浏览器中的标准实现。

## 选择器种类

### 简单选择器

- `*`               通用选择器
- `div svg|a`       类型选择器 
- `.cls`            类名选择器
- `#id`             id选择器
- `[attr=value]`    属性选择器
- `:hover`          伪类选择器
- `::before`        伪元素选择器

#### 伪类选择器

部分伪类选择器存在会影响 `CSS` 回溯匹配的规则，计算性能较差。
##### 链接/行为
- :any-link
- 🔗visited
- :hover
- :active
- :focus
- :target
##### 树结构
- :empty
- :nth-child()
- :nth-last-child()
- :first-child :last-child :only-child
##### 逻辑型
- :not伪类
- :where :has
#### 伪元素
- ::before 
- ::after 
- ::first-line 
- ::first-letter

### 复合选择器

- <简单选择器><简单选择器><简单选择器> 
- `*` 或 `tagName` 必须写在最前，伪类伪元素等放最后

### 复杂选择器

- <复杂选择器> `<SPACE>` <复杂选择器>
- <复杂选择器> `>` <复杂选择器>
- <复杂选择器> `·` <复杂选择器>
- <复杂选择器> `+` <复杂选择器>
- <复杂选择器> `||` <复杂选择器>

## 选择器优先级

```javascript
// div#a.b .c[id=x]
// 属性选择器与类选择器同级
let sp1 = [0, 1, 3, 1];

// #a:not(#b)
let sp1 = [0, 2, 0, 0];

// *.a
// * 选择器无优先级
let sp1 = [0, 0, 1, 0];

// div.a
let sp1 = [0, 0, 1, 1];
```

每一 `位` 不是简单的十进制计算，在浏览器计算中是一个很大的进制数，来避免 n 个低优先级选择器的组合优先级高于上一级的选择器优先级的情况。更安全的做法是按位比较，而不是转换成一个数值进行大小的比较，可能浏览器实现基于历史或者性能原因选择了后者。

本周实现的选择器匹配算法实现过程中能够切身的体会到浏览器匹配复杂规则时性能的消耗，特别是针对一些不能根据当前节点及父节点就进行匹配结果的属性，类似 `nth` 这种伪类选择器，为了匹配这些选择器必须编写特殊的处理函数，并且性能都不是很高。越明确的选择器进行匹配计算时的消耗相对小一些，类似 `>` 直接指定父子关系的情况，需要向上匹配的次数就会减少，而且向上匹配还需要考虑要 `贪婪` 或 `非贪婪` 的情况，也会消耗性能。

## 思考题

- 问：为什么 first-letter 可以设置 float 之类的，而 first-line 不行呢？

> 答：first-letter 和 first-line 都作用于块级元素。
> - first-letter 只对第一个字母起作用，计算量相对较小，一旦确定后其他字符的排版具有确定性。
> - first-line：作用于第一行的所有字符：需要先进行一次排版后确定了 first-line 的范围，之后根据其样式属性进行重新排版，而重新版本又可能会引起 first-line 范围的变化，有多次甚至无限次循环重新排版计算的风险，所以被禁用了。

## 总结

本周的练习我将 `toy-browser` 中的代码进行了回顾和改造，让其可以从子到父进行非贪婪匹配来确定当前节点是否符合选择器的要求，而实际浏览器实现时候有可能还需要考虑贪婪匹配的情况。从这个练习的角度出发能够理解为什么一些 `CSS` 伪类选择器规则会影响到性能，主要原因还是他们破坏当前节点只依赖父节点和本身的这种 `通用规则`，而不得不让浏览器的实现者去用各种特殊处理来兼容他们，而且还需要考虑贪婪和非贪婪的情况，可能一次匹配需要进行很多次的回溯计算去尝试不同的情况，从而降低了性能。